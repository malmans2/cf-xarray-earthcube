{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cf_xarray : Scale your analysis across datasets with less data wrangling and more metadata handling\n",
    "\n",
    "_Deepak Cherian, Mattia Almansi, Pascal Bourgault_\n",
    "\n",
    "There has been an explosion in the availability of terabyte to petabyte-scale\n",
    "geoscience datasets, particularly on the cloud, prompting the development of\n",
    "scalable tools and workflows to handle such big datasets by Earthcube projects\n",
    "such as Pangeo. There is a parallel need for tools that enable the analysis of\n",
    "datasets from a wide variety of sources that each have their own nomenclature.\n",
    "\n",
    "Xarray is a python package that enables easy and convenient labelled data\n",
    "analytics by allowing users to leverage metadata such as dimension names and\n",
    "coordinate labels. cf_xarray is an open-source Apache licensed Xarray extension\n",
    "that decodes Climate and Forecast (CF) Metadata conventions adopted by the\n",
    "geoscience community, allowing users to extensively use standardized metadata\n",
    "such as “standard names” in their analysis pipelines. For example, the zonal\n",
    "average of an Xarray dataset `ds` is seamlessly calculated as\n",
    "`ds.cf.mean(\"longitude\")` on a wide variety of CF-compliant datasets, regardless\n",
    "of the actual name of the “longitude” variable (e.g. “lon”, “lon_rho”, “long”).\n",
    "cf_xarray also provides tools and heuristics to optionally guess absent\n",
    "attributes, allowing usage on incompletely tagged datasets. cf_xarray is now\n",
    "seeing adoption in other packages such as xESMF, a package for regridding of\n",
    "Xarray datasets; and NOAA’s Model Diagnostic Task Force (MDTF) diagnostic\n",
    "workflow for validating model simulations.\n",
    "\n",
    "Our notebook will demonstrate the use of cf_xarray to build an analysis pipeline\n",
    "that works on a wide variety of cloud-available datasets such as the CMIP6\n",
    "archive, the CESM Large Ensemble, various satellite datasets, and that uses\n",
    "xESMF to regrid this wide variety of datasets to a common grid to facilitate\n",
    "analysis of anomalies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cf_xarray\n",
    "\n",
    "import xarray as xr\n",
    "import dask\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dask.config.set(**{\"array.slicing.split_large_chunks\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "\n",
    "The following functions are used in this notebook to create an example dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_example_dataset():\n",
    "\n",
    "    # Open grid and variables, then merge\n",
    "    grid = xr.open_dataset(\"data/ocean_grid_sym_OM4_05.nc\")\n",
    "    ds = xr.open_dataset(\n",
    "        \"http://35.188.34.63:8080/thredds/dodsC/OM4p5/ocean_monthly_z.200301-200712.nc4\",\n",
    "        chunks={\"time\": 1, \"z_l\": 5},\n",
    "    )\n",
    "    ds = xr.merge([grid, ds], compat=\"override\")\n",
    "\n",
    "    # Illustrate the equivalent of a curvilinear grid case,\n",
    "    # where axes and coordinates are different\n",
    "    axes = [\"xh\", \"xq\", \"yh\", \"yq\"]\n",
    "    ds = ds.drop_vars(axes)\n",
    "    ds = ds.assign_coords({axis: ds[axis] for axis in axes})\n",
    "    ds = ds.set_coords(\n",
    "        [\n",
    "            var\n",
    "            for var in ds.variables\n",
    "            for prefix in [\"geo\"]\n",
    "            if var.startswith(prefix)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def assign_coordinates_and_cell_measures(ds):\n",
    "\n",
    "    # Some CF metadata is missing in the example dataset.\n",
    "    # Datasets fully compliant with CF conventions do not need this step.\n",
    "    # Furthermore, functions to automatically assign missing coordinates\n",
    "    # and measures metadata will be implemented in cf_xarray:\n",
    "    # https://github.com/xarray-contrib/cf-xarray/issues/201\n",
    "\n",
    "    for varname, variable in ds.data_vars.items():\n",
    "\n",
    "        # Add coordinates attribute\n",
    "        coordinates = []\n",
    "        for coord in sum(ds.cf.coordinates.values(), []):\n",
    "            if set(ds[coord].dims) <= set(variable.dims):\n",
    "                coordinates.append(coord)\n",
    "        if coordinates:\n",
    "            variable.attrs[\"coordinates\"] = \" \".join(coordinates)\n",
    "        else:\n",
    "            variable.attrs.pop(\"coordinates\", None)\n",
    "\n",
    "        # Add cell_measures attribute\n",
    "        cell_measures = {}\n",
    "        for stdname in (\"cell_thickness\", \"cell_area\", \"ocean_volume\"):\n",
    "            key = stdname.split(\"_\")[-1]\n",
    "            value = ds.cf.standard_names[stdname]\n",
    "            for measure in value:\n",
    "                if (\n",
    "                    set(ds[measure].dims) <= set(variable.dims)\n",
    "                    and measure != varname\n",
    "                ):\n",
    "                    cell_measures[key] = measure\n",
    "        if cell_measures:\n",
    "            variable.attrs[\"cell_measures\"] = \" \".join(\n",
    "                [f\"{k}: {v}\" for k, v in cell_measures.items()]\n",
    "            )\n",
    "        else:\n",
    "            variable.attrs.pop(\"cell_measures\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `cf_xarray` features:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Easily access wrapped functions using xarray's API.\n",
    "\n",
    "When `cf_xarray` is imported, the `cf` accessor is automatically added to a\n",
    "dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = open_example_dataset()\n",
    "\n",
    "# cf_xarray accessor is present\n",
    "assert hasattr(ds, \"cf\")\n",
    "\n",
    "# cf_xarray preserves xarray's API\n",
    "for obj in [ds, ds.cf]:\n",
    "    assert hasattr(obj, \"squeeze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Standardize a dataset guessing missing metadata\n",
    "\n",
    "The `axis` attribute is missing in the example dataset.  \n",
    "Here we use `cf_xarray` to identify all spatial and time axes and to generate\n",
    "missing metadata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.cf.guess_coord_axis(verbose=True)\n",
    "assign_coordinates_and_cell_measures(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Concisely represent a dataset showing metadata that have been interpreted\n",
    "\n",
    "The following cell prints the representation of the `cf_xarray` accessor.  \n",
    "Note that the variables lie on staggered grids, and therefore there are multiple\n",
    "variables associated with the same Axis/Coordinate/Measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract variables using standard names\n",
    "\n",
    "`standard_name` is a CF metadata that precisely describes the physical\n",
    "quantities being represented by all variables. `cf_xarray` allows to extract\n",
    "variables using their standard names. The advantages of using standard names\n",
    "rather than variable names are:\n",
    "\n",
    "1. The code generated for a specific dataset can be applied to a wide variety of\n",
    "   datasets that each has their own nomenclature.\n",
    "2. As opposed to standard names, arbitrary variable names can be misleading.\n",
    "\n",
    "Here we use `cf_xarray` to extract the oceanic bathymetry using the appropriate\n",
    "standard name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.cf[\"sea_floor_depth_below_geoid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Identify links between variables\n",
    "\n",
    "CF conventions enable to link variables with each other using metadata (e.g.,\n",
    "`coordinates`, `cell_measures`, `ancillary_variables`).  \n",
    "For example, when we extract the bathymetry using `cf_xarray`, an additional\n",
    "variable corresponding to the surface covered by each grid cell is appended to\n",
    "the extracted `DataArray`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_coords = set(ds.cf[\"sea_floor_depth_below_geoid\"].coords)\n",
    "xr_coords = set(ds[\"deptho\"].coords)\n",
    "additional_coord = list(cf_coords - xr_coords)[0]\n",
    "ds.cf[additional_coord]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform operation on multiple dimensions associated with the same CF key\n",
    "\n",
    "As mentioned above, the example dataset has multiple dimensions associated with\n",
    "the same spatial axes.  \n",
    "Such information is decoded by `cf_xarray` and can be used by many wrapped\n",
    "functions.  \n",
    "For example, here we use the CF axes to slice multiple dimensions at once:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sliced = ds.cf.isel(X=slice(10), Y=slice(10), Z=slice(10), T=slice(10))\n",
    "print(\"Original dataset sizes:\", ds.sizes)\n",
    "print(\"  Sliced dataset sizes:\", ds_sliced.sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can apply a spatial average to all variables in the dataset\n",
    "without having to pass the arbitrary name of all staggered dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.cf.mean([\"X\", \"Y\", \"Z\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Automatically set xarray keyword arguments\n",
    "\n",
    "`cf_xarray` automatically sets some of the keyword arguments of wrapped\n",
    "functions.  \n",
    "As opposed to `xarray`, in the example below `cf_xarray` assigns the appropriate\n",
    "coordinates to the plot axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds.cf[\"sea_floor_depth_below_geoid\"]\n",
    "fig, (xr_ax, cf_ax) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "da.plot(ax=xr_ax)\n",
    "da.cf.plot(ax=cf_ax)\n",
    "_ = xr_ax.set_title(\"xarray\")\n",
    "_ = cf_ax.set_title(\"cf_xarray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Example workflow\n",
    "\n",
    "The function below performs several operations only using CF attributes.\n",
    "Therefore, it can be applied to any CF-compliant dataset.\n",
    "\n",
    "1. Fill NaN values of all cell measures with 0s\n",
    "2. Extract sea water potential temperature\n",
    "3. Select all levels shallower than 100m depth\n",
    "4. Compute and plot thickness-weighted yearly mean maps\n",
    "5. Compute and plot difference from climatology maps\n",
    "6. Compute and plot area-weighted yearly mean trend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_100m_temp(ds):\n",
    "\n",
    "    # Fill cell_measures missing values with zeros\n",
    "    for var in sum(ds.cf.cell_measures.values(), []):\n",
    "        ds[var] = ds[var].fillna(0)\n",
    "\n",
    "    # Compute and plot maps\n",
    "    with xr.set_options(keep_attrs=True):\n",
    "        da_maps = (\n",
    "            ds.cf[\"sea_water_potential_temperature\"]\n",
    "            .cf.sel(Z=slice(0, 100))\n",
    "            .cf.weighted(\"thickness\")\n",
    "            .mean([\"Z\"])\n",
    "            .cf.groupby(\"T.year\")\n",
    "            .mean()\n",
    "        )\n",
    "    da_maps = da_maps.cf.guess_coord_axis()\n",
    "    da_maps = da_maps.load()\n",
    "\n",
    "    # Plot yearly mean\n",
    "    da_maps.cf.plot(col=\"T\", center=False, robust=True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot difference from climatology\n",
    "    with xr.set_options(keep_attrs=True):\n",
    "        da_anomaly = da_maps - da_maps.cf.mean(\"T\")\n",
    "    da_anomaly.attrs[\"standard_name\"] += \"_anomaly\"\n",
    "    da_anomaly.attrs[\"long_name\"] += \" Anomaly\"\n",
    "    da_anomaly.cf.plot(col=\"T\", robust=True)\n",
    "    plt.show()\n",
    "\n",
    "    # Compute and plot yearly mean\n",
    "    da_line = da_maps.cf.weighted(\"area\").mean([\"X\", \"Y\"])\n",
    "    da_line.cf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_100m_temp(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. TODO: Apply to one of the CMIP datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run plot_top_100m_temp to one of CMIP6 datasets on Pangeo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
